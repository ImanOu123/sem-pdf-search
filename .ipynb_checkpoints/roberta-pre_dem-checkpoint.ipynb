{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "859fe1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       "    if (code_show){\n",
       "        $('div.input').hide();\n",
       "    } else {\n",
       "        $('div.input').show();\n",
       "    }\n",
       "    code_show = !code_show\n",
       "}\n",
       "$(document).ready(code_toggle);\n",
       "</script>\n",
       "Click <a href=\"javascript:code_toggle()\">here</a> to toggle on/off the code cells."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.input').hide();\n",
    "    } else {\n",
    "        $('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "}\n",
    "$(document).ready(code_toggle);\n",
    "</script>\n",
    "Click <a href=\"javascript:code_toggle()\">here</a> to toggle on/off the code cells.''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c6ffe8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d1a4e4edcf4161b4e8de3928b93a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create the file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='',  # Accepted file types (e.g., '.txt', '.pdf', '.jpg', '.csv', etc.); leave empty for all file types\n",
    "    multiple=True  # Set to True if you want to allow multiple files to be uploaded\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "file_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "240cf634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a759774f36f4e94b72237dc67c34728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Load the data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages: 100%|█████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages: 100%|█████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:06<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import PyPDF2\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "documents = []\n",
    "embeddings = []\n",
    "uploaded_file_data = []\n",
    "\n",
    "def create_embeddings(documents, model_name=\"paraphrase-MiniLM-L6-v2\"):\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else print(\"cpu\"))\n",
    "    model = SentenceTransformer(model_name)\n",
    "    #model.to(\"cuda\")\n",
    "    embeddings = model.encode(documents)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def split_string(input_string, chunk_size):\n",
    "    return [input_string[i:i+chunk_size] for i in range(0, len(input_string), chunk_size)]\n",
    "\n",
    "def upload_file(file_upload, i):\n",
    "    global documents\n",
    "    global embeddings\n",
    "\n",
    "    text_content = ''\n",
    "\n",
    "    # Get the uploaded file's content\n",
    "\n",
    "    for file, attributes in file_upload.value.items():\n",
    "        content = attributes.get('content') \n",
    "        uploaded_file_data.append(content)    \n",
    "    \n",
    "    uploaded_file_content = uploaded_file_data[i]\n",
    "\n",
    "    # Convert the uploaded file content to a readable file-like buffer\n",
    "    file_buffer = io.BytesIO(uploaded_file_content)\n",
    "\n",
    "    # Read the PDF file using PyPDF2\n",
    "    pdf_reader = PyPDF2.PdfReader(file_buffer)\n",
    "\n",
    "    # Extract the text content from the PDF\n",
    "    text_content = ''\n",
    "    for page_num in tqdm(range(len(pdf_reader.pages)), desc='Processing pages'):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text_content += page.extract_text()\n",
    "\n",
    "    # on last iteration add the information to documents and embeddings\n",
    "    if page_num == (len(pdf_reader.pages)-1):\n",
    "        documents.append(split_string(text_content, 1000))\n",
    "    \n",
    "        # Create document embeddings for semantic search\n",
    "        embeddings.append(create_embeddings(documents[i]))        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "for file, attributes in file_upload.value.items():\n",
    "    content = attributes.get('content') \n",
    "    uploaded_file_data.append(content)\n",
    "    \n",
    "button = widgets.Button(description=\"Load the data\")\n",
    "\n",
    "def on_button_click(b):\n",
    "    if file_upload.value:\n",
    "        for i in range(len(file_upload.value)):\n",
    "            upload_file(file_upload, i)\n",
    "            print(\"Data loaded successfully!\")\n",
    "    else:\n",
    "        print(\"No files uploaded\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "55bdc6d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876fc60b41f64897ace99f70af818821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Enter your question here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8919cb58bd5427d811702f3be3e7325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def retrieve_passages(query, documents, embeddings, top_k=5):\n",
    "    model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "    #model.to(\"cuda\")\n",
    "\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    similarities = cosine_similarity(query_embedding.reshape(1, -1), embeddings)\n",
    "\n",
    "    #top_indices = np.argsort(similarities[0])[-top_k:][::-1]\n",
    "\n",
    "    threshold = 0.4  \n",
    "    top_indices = np.argsort(similarities[0])[::-1][:top_k][similarities[0][np.argsort(similarities[0])[::-1][:top_k]] >= threshold]\n",
    "\n",
    "    \n",
    "    #print(similarities[0])\n",
    "    #print(top_indices)\n",
    "    return [documents[i] for i in top_indices]\n",
    "\n",
    "def extract_answer(question, passage, model_name=\"roberta-large\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer.encode_plus(question, str(passage), return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length', return_offsets_mapping=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    offset_mapping = inputs[\"offset_mapping\"].squeeze(0)\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits)\n",
    "\n",
    "    answer_start_char = offset_mapping[answer_start][0]\n",
    "    answer_end_char = offset_mapping[answer_end][1]\n",
    "    answer = passage[answer_start_char:answer_end_char]\n",
    "\n",
    "    return answer\n",
    "\n",
    "def qa_system(question, documents, embeddings, model_name=\"roberta-large\", top_k=5):\n",
    "        answers = []\n",
    "        keys = list(file_upload.value.keys())\n",
    "\n",
    "        # iterate over all files to extract answers from each one\n",
    "        for i in range(len(documents)):\n",
    "            passages = retrieve_passages(question, documents[i], embeddings[i], top_k=top_k)\n",
    "        \n",
    "            #print(passages)\n",
    "        \n",
    "            for passage in passages:\n",
    "                answer = extract_answer(question, passage, model_name=model_name)\n",
    "                answers.append({\"fileName\" : file_upload.value[keys[i]]['metadata']['name'], \"answer\": answer, \"context\": passage})\n",
    "\n",
    "        return answers\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# This function is called when the button is clicked\n",
    "\n",
    "# Create the text field and button widgets\n",
    "text_field = widgets.Text(placeholder='Enter your question here')\n",
    "button = widgets.Button(description='Search')\n",
    "\n",
    "answers = []\n",
    "first = False\n",
    "\n",
    "\n",
    "def on_button_click(button):\n",
    "    global first\n",
    "    \n",
    "    %clear\n",
    "    clear_output(wait=True)\n",
    "    first = False\n",
    "    # Get the text input from the text field\n",
    "    text_input = text_field.value\n",
    "    # Display the widgets\n",
    "    text_field.value = text_input\n",
    "    display(text_field, button)   \n",
    "    \n",
    "    \n",
    "    print(\"Generating answers, please wait...\")\n",
    "    # Retrieve answers using the QA system\n",
    "    global answers\n",
    "    answers = qa_system(text_input, documents, embeddings)\n",
    "\n",
    "#     # Print the answers\n",
    "#     for idx, answer in enumerate(answers):\n",
    "#         print(f\"Document : {answer['fileName']}, Answer {idx + 1}: {answer['answer']}\\nContext: {answer['context']}\\n\")   \n",
    "        \n",
    "    \n",
    "\n",
    "    if not answers: print(\"No answers available\")\n",
    "    \n",
    "    show_results()\n",
    "    # Call your function with the input and print the result\n",
    "    #result = your_function(text_input)\n",
    "    #print(result)\n",
    "\n",
    "\n",
    "\n",
    "# Set the callback function for the button\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_field, button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b2b6eba2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, IFrame\n",
    "import fitz \n",
    "import functools\n",
    "import string\n",
    "import os, sys, subprocess\n",
    "import webbrowser\n",
    "        \n",
    "    \n",
    " \n",
    "    \n",
    "#show_results()        \n",
    "    \n",
    "    \n",
    "def preprocess_context(context):\n",
    "    # removing hyphen, newline and non-ascii characters\n",
    "    contextFix = (context).replace(\"-\", \"\")\n",
    "\n",
    "    ascii_chars = set(string.printable)\n",
    "    contextFix = ''.join(filter(lambda x: x in ascii_chars, contextFix))\n",
    "\n",
    "    contextFixLst = contextFix.split(\"\\n\")\n",
    "\n",
    "    contextFixLstWOWhite = []\n",
    "    for contextFix in contextFixLst:\n",
    "        if not all(ch==\" \" for ch in contextFix):\n",
    "            contextFixLstWOWhite.append(contextFix)\n",
    "            \n",
    "    # split content into a list of lines\n",
    "    return contextFixLstWOWhite\n",
    "\n",
    "\n",
    "\n",
    "def clear_file():\n",
    "    if fileToClear != '':\n",
    "        pdfDoc = fitz.open(fileToClear)\n",
    "    \n",
    "        # iterates pages and removes annotations generated by fitz\n",
    "        for pgNum in range(len(pdfDoc)):\n",
    "            page = pdfDoc[pgNum]\n",
    "    \n",
    "            pdfDoc.xref_set_key(page.xref, \"Annots\", \"[]\")\n",
    "        \n",
    "        pdfDoc.save(fileToClear, incremental=True, encryption=fitz.PDF_ENCRYPT_KEEP)\n",
    "\n",
    "        # clear output cell \n",
    "        out.clear_output()\n",
    "        outPgNum.clear_output()\n",
    "\n",
    "def clear_btn_click(button): clear_file();\n",
    "\n",
    "def open_file(filename, pgNum):\n",
    "    currDir = os.getcwdb()\n",
    "    \n",
    "    # opens file in default browser at specific page, NOTE: assumes that file is in current directory and Chrome is installed\n",
    "    fileLoc = \"file:///\" + str(currDir)[2:][:-1] + \"/\" + filename + \"#page=\" + str(pgNum)\n",
    "    (webbrowser.get(using='chrome')).open(fileLoc)      \n",
    "    \n",
    "    \n",
    "def show_results():\n",
    "    \n",
    "\n",
    "\n",
    "    # button to remove highlight and clear output \n",
    "    fileToClear = ''\n",
    "    clearBtn = widgets.Button(description=\"Clear\")\n",
    "\n",
    "    foundPgNum = -1   \n",
    "    \n",
    "    # to display relevant PDF\n",
    "    out = widgets.Output(layout={'border': '1px solid white', 'width':'950px', 'height':'600px'})\n",
    "\n",
    "    # to display page number\n",
    "    outPgNum = widgets.Output(layout={'width':'300px', 'height':'50px'})    \n",
    "\n",
    "\n",
    "    clearBtn.on_click(clear_btn_click)\n",
    "    display(clearBtn)\n",
    "\n",
    "    # iterate through all answers \n",
    "    for idx, answer in enumerate(answers):\n",
    "\n",
    "        # display answer\n",
    "        label = widgets.HTML(value=\"<style>p{word-wrap: break-word}</style> <p> File Name: \" + answer['fileName'] + \"</p>\"  + \"\\n<p> Context: \" + answer['context'] + \"</p>\")\n",
    "        display(label)\n",
    "\n",
    "        # button to highlight context on original PDF\n",
    "        button = widgets.Button(description='Citation')\n",
    "\n",
    "        def on_button_click(button, fileInfo=(\"\", \"\")):\n",
    "            global foundPgNum\n",
    "            global fileToClear\n",
    "            global first\n",
    "            \n",
    "            if not first:\n",
    "                display(out)\n",
    "\n",
    "                display(outPgNum)      \n",
    "                \n",
    "                first = True\n",
    "            \n",
    "            # if direct change from file to file, clear previous file\n",
    "            clear_file()\n",
    "\n",
    "            pdfDoc = fitz.open(fileInfo[0])        \n",
    "            found = False\n",
    "\n",
    "            # iterate through pages in file\n",
    "            for pgNum in range(len(pdfDoc)):\n",
    "                foundTxtLst = []\n",
    "                page = pdfDoc[pgNum]            \n",
    "                #print(fileInfo[1])\n",
    "                #contextLst = preprocess_context(fileInfo[1])\n",
    "                #contextLst = fileInfo[1].split('\\n')\n",
    "\n",
    "                contextLst = [line for line in fileInfo[1].split('\\n') if line.strip() not in {\"\", \"-\", \"/\", \".\"}]\n",
    "\n",
    "\n",
    "                # highlight sections and open file\n",
    "                for context in contextLst:\n",
    "                    # append to list of highlight rect to make a continuous rect\n",
    "                    foundTxt = page.search_for(context)\n",
    "                    #print('searching context: ', context, 'in page ', pgNum)\n",
    "\n",
    "\n",
    "\n",
    "                    if foundTxt: \n",
    "                        # save pg number of where context is found\n",
    "                        if not found: \n",
    "                            foundPgNum = pgNum + 1\n",
    "                            found = True\n",
    "                            #print('found2 ', foundTxt, foundPgNum)\n",
    "                        foundTxtLst = foundTxtLst + foundTxt\n",
    "\n",
    "                        \n",
    "                        \n",
    "                extra_width = 150\n",
    "                # make more continuous highlight rect including all of the smaller rects of the found text\n",
    "                if foundTxtLst:\n",
    "\n",
    "                    #print('found text ', foundTxtLst)\n",
    "\n",
    "                    # find leftmost and rightmost point of highlight on page\n",
    "                    leftX = foundTxtLst[0].top_left.x\n",
    "                    leftY = foundTxtLst[0].top_left.y\n",
    "                    rightX = foundTxtLst[-1].bottom_right.x\n",
    "                    rightY = foundTxtLst[-1].bottom_right.y\n",
    "\n",
    "                    for rect in foundTxtLst:\n",
    "                        if rect.top_left.x < leftX:\n",
    "                            leftX = rect.top_left.x\n",
    "                        if rect.top_left.y < leftY:\n",
    "                            leftY = rect.top_left.y\n",
    "                        if rect.bottom_right.x > rightX:\n",
    "                            rightX = rect.bottom_right.x\n",
    "                        if rect.bottom_right.x > rightY:\n",
    "                            rightY = rect.bottom_right.y\n",
    "\n",
    "                    # Adjust leftX and rightX for the extra width\n",
    "                    leftX -= extra_width + 100\n",
    "                    rightX += extra_width\n",
    "\n",
    "                    page.add_highlight_annot(fitz.Rect(fitz.Point(leftX, leftY), \n",
    "                                                       fitz.Point(rightX, rightY)))\n",
    "\n",
    "            pdfDoc.save(fileInfo[0], incremental=True, encryption=fitz.PDF_ENCRYPT_KEEP)\n",
    "            fileToClear = fileInfo[0]\n",
    "            \n",
    "            open_file(fileInfo[0], foundPgNum)\n",
    "            #os.system(\"open -a Preview /Users/elkindi/cfpb_complaint-bulletin_crypto-assets_2022-11.pdf -g -p 20\")\n",
    "\n",
    "            # clear output cell and render new file\n",
    "            out.clear_output()\n",
    "#             @out.capture()\n",
    "#             def render():\n",
    "#                 display(IFrame(src=fileInfo[0],width=1000, height=600))\n",
    "#             render()\n",
    "\n",
    "#             outPgNum.clear_output()\n",
    "#             @outPgNum.capture()\n",
    "#             def renderPgNum():\n",
    "#                 display(HTML(\"<p> File Name: \" + fileInfo[0] + \"</p>\"))\n",
    "#                 display(HTML(\"<p> Page Number: \" + str(foundPgNum) + \"</p>\"))\n",
    "#             renderPgNum()\n",
    "\n",
    "        button.on_click(functools.partial(on_button_click, fileInfo=(answer['fileName'], answer['context'])))\n",
    "        display(button)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ee1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
